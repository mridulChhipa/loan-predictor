{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeb6d713-6834-4a6f-b5ae-c2d66f2b2638",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 020: Loss=0.5006, Train Acc=0.8058\n",
      "Epoch 040: Loss=0.4128, Train Acc=0.8590\n",
      "Epoch 060: Loss=0.3691, Train Acc=0.8576\n",
      "Epoch 080: Loss=0.3439, Train Acc=0.8608\n",
      "Epoch 100: Loss=0.3273, Train Acc=0.8623\n",
      "Test Accuracy: 0.9135\n",
      "âœ… Model data saved for DYNAMIC explanations!\n",
      "ðŸš« No stored explanations - all explanations computed on-demand\n",
      "ðŸ“Š Features: 52\n",
      "ðŸŽ¯ Background samples for SHAP: 100\n",
      "âœ… ONNX model saved\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.onnx\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import json\n",
    "import pickle\n",
    "\n",
    "import shap\n",
    "import lime.lime_tabular"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6172ad39",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_wa = pd.read_csv(r\"hmda_2016_wa_all-records_labels.csv\", low_memory=False)\n",
    "df_ak = pd.read_csv(r\"hmda_2016_ak_all-records_labels.csv\", low_memory=False)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9aa1d45",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogisticRegression(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super().__init__()\n",
    "        self.linear = nn.Linear(input_dim, 1)\n",
    "    def forward(self, x):\n",
    "        return torch.sigmoid(self.linear(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d097e1b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_to_use = [\n",
    "    'loan_type_name', 'loan_purpose_name', 'loan_amount_000s',\n",
    "    'applicant_income_000s', 'property_type_name', 'purchaser_type_name',\n",
    "    'owner_occupancy_name', 'applicant_ethnicity_name', 'preapproval_name',\n",
    "    'lien_status_name', 'sequence_number',\n",
    "    'number_of_owner_occupied_units', 'number_of_1_to_4_family_units',\n",
    "    'hud_median_family_income', 'tract_to_msamd_income',\n",
    "    'applicant_race_name_1', 'applicant_sex_name', 'action_taken'\n",
    "]\n",
    "\n",
    "train_df = df_wa[cols_to_use].copy()\n",
    "test_df = df_ak[cols_to_use].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36870dae",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_cols = [\n",
    "    'applicant_income_000s', 'number_of_owner_occupied_units',\n",
    "    'number_of_1_to_4_family_units', 'hud_median_family_income',\n",
    "    'tract_to_msamd_income'\n",
    "]\n",
    "\n",
    "for col in num_cols:\n",
    "    med_train = train_df[col].median()\n",
    "    med_test = test_df[col].median()\n",
    "    train_df[col] = train_df[col].fillna(med_train)\n",
    "    test_df[col] = test_df[col].fillna(med_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f784cda2",
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_cols = [\n",
    "    'loan_type_name', 'loan_purpose_name', 'property_type_name',\n",
    "    'purchaser_type_name', 'owner_occupancy_name',\n",
    "    'applicant_ethnicity_name', 'preapproval_name',\n",
    "    'lien_status_name', 'applicant_race_name_1', 'applicant_sex_name'\n",
    "]\n",
    "numerical_cols = [\n",
    "    'loan_amount_000s', 'applicant_income_000s', 'sequence_number',\n",
    "    'number_of_owner_occupied_units', 'number_of_1_to_4_family_units',\n",
    "    'hud_median_family_income', 'tract_to_msamd_income'\n",
    "]\n",
    "target = 'action_taken'\n",
    "\n",
    "train_ohe = pd.get_dummies(train_df, columns=categorical_cols, drop_first=False)\n",
    "test_ohe = pd.get_dummies(test_df, columns=categorical_cols, drop_first=False)\n",
    "train_ohe, test_ohe = train_ohe.align(test_ohe, join='left', axis=1, fill_value=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0c73c99",
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_binary(code):\n",
    "    approved = {1,2,6,8}\n",
    "    return 1 if code in approved else 0\n",
    "\n",
    "y_train = train_ohe[target].apply(to_binary).values\n",
    "X_train = train_ohe.drop(columns=[target]).values\n",
    "y_test = test_ohe[target].apply(to_binary).values\n",
    "X_test = test_ohe.drop(columns=[target]).values\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "X_train_tensor = torch.tensor(X_train_scaled, dtype=torch.float32).to(device)\n",
    "y_train_tensor = torch.tensor(y_train.reshape(-1,1), dtype=torch.float32).to(device)\n",
    "X_test_tensor = torch.tensor(X_test_scaled, dtype=torch.float32).to(device)\n",
    "y_test_tensor = torch.tensor(y_test.reshape(-1,1), dtype=torch.float32).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18793b5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LogisticRegression(X_train_tensor.shape[1]).to(device)\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06da4ed5",
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(1, 101):\n",
    "    model.train()\n",
    "    preds = model(X_train_tensor)\n",
    "    loss = criterion(preds, y_train_tensor)\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    if epoch % 20 == 0:\n",
    "        with torch.no_grad():\n",
    "            acc = ((preds>=0.5).float()==y_train_tensor).float().mean().item()\n",
    "        print(f\"Epoch {epoch:03d}: Loss={loss.item():.4f}, Train Acc={acc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a52effef",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    prob_test = model(X_test_tensor)\n",
    "    acc_test = ((prob_test>=0.5).float()==y_test_tensor).float().mean().item()\n",
    "    print(f\"Test Accuracy: {acc_test:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d2484fa-7533-4c40-a303-19461d2fb1ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names = train_ohe.drop(columns=[target]).columns.tolist()\n",
    "\n",
    "weights = model.linear.weight.detach().cpu().flatten().numpy().tolist()\n",
    "bias = model.linear.bias.detach().cpu().item()\n",
    "scaler_mean = scaler.mean_.tolist()\n",
    "scaler_scale = scaler.scale_.tolist()\n",
    "\n",
    "background_data = X_train_scaled[:100].tolist()\n",
    "\n",
    "model_data = {\n",
    "    \"weights\": weights,\n",
    "    \"bias\": bias,\n",
    "    \"scaler_mean\": scaler_mean,\n",
    "    \"scaler_scale\": scaler_scale,\n",
    "    \"feature_names\": feature_names,\n",
    "    \"background_data\": background_data, \n",
    "    \"feature_categories\": {\n",
    "        \"numerical\": numerical_cols,\n",
    "        \"categorical\": categorical_cols\n",
    "    },\n",
    "    \"dynamic_explanations\": True \n",
    "}\n",
    "\n",
    "with open('model_data.json', 'w') as f:\n",
    "    json.dump(model_data, f, indent=2)\n",
    "\n",
    "model_cpu = model.cpu().eval()\n",
    "dummy_in = torch.randn(1, X_train_tensor.shape[1], dtype=torch.float32)\n",
    "torch.onnx.export(\n",
    "    model_cpu, dummy_in, \"logistic_regression_model.onnx\",\n",
    "    export_params=True, opset_version=11, do_constant_folding=True,\n",
    "    input_names=['input'], output_names=['output'],\n",
    "    dynamic_axes={'input':{0:'batch_size'}, 'output':{0:'batch_size'}}\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
